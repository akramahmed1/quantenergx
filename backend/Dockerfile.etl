# Dockerfile for ETL Service - ORC Data Lake Pipeline
FROM node:20-alpine AS builder

WORKDIR /app

# Install build dependencies
RUN apk add --no-cache python3 make g++

# Copy package files
COPY package*.json ./

# Install dependencies including native modules
RUN npm ci --only=production && npm cache clean --force

# Production stage
FROM node:20-alpine AS production

# Install system dependencies for ETL processing
RUN apk update && apk upgrade && \
    apk add --no-cache \
    curl \
    python3 \
    py3-pip \
    tzdata \
    dumb-init \
    libstdc++ \
    && rm -rf /var/cache/apk/*

# Create non-root user
RUN addgroup -g 1001 -S etl && \
    adduser -S etl -u 1001 -G etl

WORKDIR /app

# Copy dependencies and source
COPY --from=builder --chown=etl:etl /app/node_modules ./node_modules
COPY --chown=etl:etl package.json ./
COPY --chown=etl:etl etl/ ./etl/

# Create necessary directories
RUN mkdir -p logs temp data && \
    chown -R etl:etl /app

# Set environment variables
ENV NODE_ENV=production
ENV ETL_SCHEDULE_ENABLED=true
ENV ETL_BATCH_SIZE=1000
ENV DATA_RETENTION_DAYS=2555

# Health check specific to ETL service
HEALTHCHECK --interval=60s --timeout=30s --start-period=120s --retries=3 \
    CMD node -e "console.log('ETL service health check')" || exit 1

# Switch to non-root user
USER etl

# Use dumb-init for proper signal handling
ENTRYPOINT ["dumb-init", "--"]

# Start ETL service
CMD ["node", "etl/oilPricesETL.js"]